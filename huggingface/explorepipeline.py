import torch
import os
from huggingface_hub import login
from transformers import pipeline
from diffusers import DiffusionPipeline
from datasets import load_dataset
import soundfile as sf
from IPython.display import Audio
from dotenv import load_dotenv

def loadDotenvAndCheckAPIKey():
    load_dotenv(override=True)
    huggingface_api_key = os.getenv('HF_TOKEN')

    if not huggingface_api_key:
        raise ValueError("HuggingFace API key not found in environment variables")
    if huggingface_api_key and huggingface_api_key.startswith('hf_') and len(huggingface_api_key)>10:
        print("API key looks good so far")
    else:
        print("There might be a problem with your API key? Please visit the troubleshooting notebook!")
    return huggingface_api_key


def run_sentiment_analysis(text):
    classifier = pipeline("sentiment-analysis")
    result = classifier(text)
    print( result[0].get('label') )
    print( result[0].get('score') )
    print(result)

def run_named_entity_recognition(text):
    ner = pipeline("ner", grouped_entities=True)
    result = ner(text)
    for index in result:
        print(f' Entity Group : {index["entity_group"]}' )
        print(f' Score : {index["score"]}')
        print(f' Word : {index["word"]}')
    print(result)

def run_question_answer(question, context):
    question_answerer = pipeline("question-answering")
    result = question_answerer(question=question, context=context)
    print(f' Score  : {result.get("score")}')
    print(f' Answer : {result.get("answer")}')
    print(result)

def run_text_summarization():

    summarizer = pipeline("summarization", model="sshleifer/distilbart-cnn-12-6")

    text = """The Hugging Face transformers library is an incredibly versatile and powerful tool for natural language processing (NLP).
    It allows users to perform a wide range of tasks such as text classification, named entity recognition, and question answering, among others.
    It's an extremely popular library that's widely used by the open-source data science community.
    It lowers the barrier to entry into the field by providing Data Scientists with a productive, convenient way to work with transformer models.
    """
    summary = summarizer(text, max_length=50, min_length=25, do_sample=False)
    print("Summary as follows")
    print(summary[0]['summary_text'])

def run_translations_en_to_fr():
    translator = pipeline("translation_en_to_fr")
    result = translator("The Data Scientists were truly amazed by the power and simplicity of the HuggingFace pipeline API.")
    print(result[0]['translation_text'])

def run_classification():
    classifier = pipeline("zero-shot-classification")
    result = classifier("Hugging Face's Transformers library is amazing!", candidate_labels=["technology", "sports", "politics"])
    print(result)

def run_text_generation():
    generator = pipeline("text-generation")
    result = generator("If there's one thing I want you to remember about using HuggingFace pipelines, it's")
    print(result[0]['generated_text'])

def run_image_generation():
    image_gen = DiffusionPipeline.from_pretrained(
        "stabilityai/sdxl-turbo",
        torch_dtype=torch.float32,  # Use standard floating point instead of float8
        use_safetensors=True,
        variant="fp16"  # This is fine, as it refers to how weights are stored
    ).to("cpu")
    text = "A class of Data Scientists learning about AI, in the surreal style of Salvador Dali"
    image = image_gen(prompt=text).images[0]
    image
def run_audio():
    synthesiser = pipeline("text-to-speech", "microsoft/speecht5_tts")

    embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation")
    speaker_embedding = torch.tensor(embeddings_dataset[7306]["xvector"]).unsqueeze(0)

    speech = synthesiser("This is my first audio clip which will be generated by Gen AI using text to speech pipeline on Hugginggface! ", forward_params={"speaker_embeddings": speaker_embedding})

    sf.write("speech.wav", speech["audio"], samplerate=speech["sampling_rate"])
    os.system("start speech.wav")

if __name__ == '__main__':
    login(loadDotenvAndCheckAPIKey(), add_to_git_credential=True)
    # run_sentiment_analysis("I'm  super excited to be on the way to LLM mastery!")
    # run_named_entity_recognition("Barack Obama was the 44th president of the United States.")
    # run_question_answer("Who was the 44th president of the United States?", "Barack Obama was the 44th president of the United States.")
    # run_text_summarization()
    # run_translations_en_to_fr()
    # run_classification()
    # run_text_generation()
    # run_image_generation()
    run_audio()